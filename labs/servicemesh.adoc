:hide-uri-scheme:
== OpenShift Service Mesh [INNOVATION]

Author: Mark Roberts (feedback to mroberts@redhat.com)

=== Introduction

OpenShift is a platform that enables developers to deliver and manage extremely complex polyglot applications covering a variety of language runtimes and underlying technologies. However, OpenShift to date has not provided controls and monitoring regarding how each application component interacts with other components within an application or wider enterprise. This is where the Red Hat OpenShift Service Mesh adds value to the development and operations staff responsible for applications. 

Red Hat OpenShift Service mesh is comprised of a number of separate open source projects that have been tested and integrated as a whole to deliver value to the OpenShift user. Each open source project breaks down further to specific named elements, some of which are encountered and described in the following workshop chapter. 


==== Istio

Istio is an implementation of the service-mesh and this component is responsible for the overall management of communication traffic between the elements of the application. The service mesh provides the manageable and measurable interaction between different services and enables teams to introduce new functionality and services in a controlled manner. One of the major benefits of the service-mesh is the fact that functionality such as Load balancing, resilience, security and observation is delivered by the mesh and not by the application. Application developers can focus in the value of their application and not how to add the resilience etc. to the application. In the earlier chapter on 'Application deployment strategies' users created a mechanism for blue/green deployments and A/B deployments to spread the load across different versions of services. These capabilities are extended further with Istio in terms of the basis for the rules that are used for traffic management. For a more detailed introduction to Istio please take a look at the free O'Reilly book 'Introducing Istio Service Mesh for Microservices' which can be downloaded from https://developers.redhat.com/books/introducing-istio-service-mesh-microservices/[here, window="_blank"]. 

==== Kiali 

Kiali provides the observability capability to the Red Hat Service Mesh. This enables users to build a picture of service interaction, observe traffic and look in detail at the resources that are added to the OpenShift platform to create the operational service mesh. Kiali is used to understand the structure of the mesh and to gather metrics. A link is available to from Kiali to Jaeger for distributed tracing.

==== Jaeger

Jaeger provides a detailed distributed traffic tracing capability. This shows accurately message interaction and enables teams to understand in detail the sequencing of traffic flow and to identify bottlenecks and weaknesses within the mesh.
 
=== Using Red Hat Service Mesh

The following workshop steps will show you how to create a service mesh using a simple application. The application communication will work perfectly fine with the use of OpenShift services and routes, and the introduction of the service mesh to provide more capable communication management will have no implications on the application code.

The application is called layers and it is a very simple Node JS REST interface that receives request either from an external curl command or from another version of itself. The application uses a number of environment variables that are set within the deployment yaml files. If the application instance has an environment variable called NEXT_LAYER_NAME then it will send a message to that layer. This continues down the layers of communication until an application instance is reached that does not have the environment variable. With each response the application returns its name, version identifier and IP address.

==== Create a new project for the service mesh activity

[source]
----
oc new-project service-mesh-{{USER_ID}}
----

Not all projects are required to be managed by service mesh. As a result you need to add the project that you just created to the service mesh control plane so that the sidecar containers will be injected into the pods. We will be using some preloaded assets in the Terminal window, so enter the following command to set the context: 

[source]
----
cd /workspace/workshop4/attendee/service-mesh
----

To add the current project as a service mesh member within the control plane called 'istio-system' execute the command :

[source]
----
oc create -f servicemeshmember.yaml
----

=== Phase 1 - Initial application

The micro-service based application that you are about to create is very simple and uses a rest interface that can be asked to call another downstream version of itself. This can continue for as many application instances as needed to illustrate the features of the service mesh. 

To create the first application instance do the following :

[source]
----
cd phase1
oc create -f layer1.yaml --save-config
----

Switch to the web user interface and select the developer view for your service mesh project. Select the topology view and you will see the application start to be created. Click on the centre of the blue circle for the application and you should see the fly out menu on the right with details of the service and the running pod on the resources tab. Select the pod and scroll down the details of the pod until you see a section titled 'Containers'. This should show two containers as indicated below which are the 'layers' application container and the Istio sidecar container.

image::service-mesh-01.png[Pod with application container and sidecar container]

Expose the service using a route by executing the following command :

[source]
----
oc expose service/layer1
----

At this point the application has all of the components required for network communication without the use of Istio. The resources required that exist can be viewed with the command :

[source]
---- 
oc get all
----

This will list the following resources :

* deployment
* pod
* replicaset
* service
* route

The route, service and pod are shown in the diagram below to indicate the network communication to the application.

image::service-mesh-02.png[Route, service and application]

Communication to the application will work as expected using the above resources. This can be tested by pasting the following command into the terminal window to make 100 calls to the application, approximately ever 0.2 seconds. 

[source]
----
export ROUTE=$(oc get route -o jsonpath='{.items[0].spec.host}{"/call-layers"}')
for i in {1..100}; do curl $ROUTE; echo ""; sleep .2;done
----

==== Adding Istio capability

To enable the service mesh communication requires further resources to be created. The initial resources to be created are the gateway and the virtual service. The gateway resource identifies a host for which communication should be intercepted and directed to the istio-ingress gateway. The virtual service  acts as a communication director selecting traffic that matches specific criteria for routing to a destination service. The gateway and virtual service yaml content is shown in the diagram below which also shows schematically how the communication is directed.

image::service-mesh-03.png[Istio gateway and virtual service]

Create the gateway and the virtual service with the commands below:

[source]
----
oc create -f gateway-layer1.yaml
oc create -f virtual-service-layer1.yaml
----

==== View the istio related resources

The oc command 'oc get all' is often used to generate a list of all resources within a project. This is fine for listing the deployment configurations, services, replicasets and pods but it does not list the resources used to manage the service mesh. To view the istio related resources use the command below :

[source]
----
oc get istio-io
----

The above command will list the gateway and the virtual service. The virtual service also shows the gateway to which it relates and the hosts for which it is controlling traffic as shown in the example below.

[source]
----
NAME                                        GATEWAYS           HOSTS                                                        AGE
virtualservice.networking.istio.io/layers   [layer1-gateway]   [layer1-layers.apps.cluster-c2d5.c2d5.example.opentlc.com]   54s

NAME                                         AGE
gateway.networking.istio.io/layer1-gateway   63s
----

=== Service mesh visualisation with Kiali

Red Hat Service mesh includes a component called Kiali which provides a visualization of the components of the mesh to assist in monitoring and managing the communication processes within a micro-service based application. To find the URL for the Kiali web application enter the command :

[source]
----
echo "kiali-istio-system."$(oc whoami --show-console=true | cut -d'.' -f2-7)
----

This command will create the URL for the Kiali system in use within the cluster. Open this URL in a new browser tab.

Press the blue 'Log In With OpenShift' button to authenticate with your OpenShift credentials and then select the blue '1 application' link in the box labelled with your service-mesh-{{USER_ID}} project.

On the left hand side of the Kiali screen select 'Graph and you should see a screen similar to that shown below :

image::service-mesh-04.png[Kiali initial screen]

If your screen shows application nodes and services then Kiali is responding to the traffic that was sent in the 100 calls to the application a few minutes ago. Kiali will display a discovered configuration of applications and services if there has recently been traffic for it to observe.

If the Kiali view has timed out and removed the discovered services you will see a screen identical to that which is shown above. In that case press the blue button with the text 'Display unused nodes' and you will see the nodes and services of the application.

You will now see the layer-1 application which is broken out as the service (dotted triangle) and the application (dotted square). Press the legend button to see the key to the objects in the browser window. You will also see that the service has an Istio virtual service associated with it.

Press the display drop down menu at the top of the screen and select the traffic animation option. Back at the terminal window start sending traffic to the service again using the for loop shell script used previously (and repeated below) :

[source]
----
for i in {1..100}; do curl $ROUTE; echo ""; sleep .2;done
----

Switch back to the Kiali window and watch the animation of the traffic flow in the graph. It will take a few seconds for the animation to start, but eventually you will see a screen similar to that which is shown below. 

image::service-mesh-05.png[Kiali traffic animation]

Kiali has a number of sources of information which are selected from the left hand side menu. The animation display is shown on the graph view. If the for loop to send requests to the application has ended then restart it and you may want to change the number of calls to 1000 and change the sleep delay to 0.5 or 1.0 seconds to give more traffic while you explore the user interface.

On the Kiali graph view click on the service (triangle) for layer1 and you will see information about the service on the right hand side panel. The panel shows information about the messages entering and leaving the service. Click on the application for layer1, identified as v1 (square) and the right hand side panel changes to display information about the application which only has inbound traffic.

The top menu of the Graph screen has a number of different viewing modes. The first drop down menu allows users to display information on different versions of applications, to only show services or to display the workloads. The versioned application graph is particularly useful as it groups multiple versions of applications together along with their associated services.

The second drop down menu allows for the display of requests per second, request percentage and response time on each communication line. The request percentage is particularly useful when splitting traffic between versions later.

The third drop down menu allows users to select which objects to display on the main screen.

On the left hand side of the Kiali screen there are options to display information about applications, workloads and services. These displays show useful information on the health of the resource. The Istio Config menu shows information about the istio resources (virtual services, gateways and many other Istio related resources). This is a useful source of information if something is wrong in the configuration of a resource as it will be highlighted clearly as shown below.

image::service-mesh-06.png[Virtual service with error]

=== Phase 2 - Further content in the communication chain

The next phase of building the service mesh is to introduce another application and service. 

Change directory to phase 2 and create the new application for layer 2 with the following commands:

[source]
----
cd ../phase2
oc create -f layer2.yaml --save-config
----

In the topology view of the web user interface you will see that two deployments are created for the two different versions of layer2, with two pods for each application.

Create the additional virtual service for the component with the commands:

[source]
----
oc create -f virtual-service-layer2.yaml --save-config
----

Reconfigure layer1 to send messages to layer2 using the command:

[source]
----
oc apply -f layer1.yaml
----

Switch to the OpenShift browser window and ensure that you are using the developer mode on the top left corner, you have the service-mesh-{{USER_ID}} project selected and you are viewing the Topology view. You should see the 'layers' application grouping with layer1-v1 and layer2 (with versions v1 and v2) grouped together within the application group. Click on layer1-v1 and you will see on the fly-out window on the right hand side that it has one pod. This pod contains the running application container and the istio sidecar container too. If you select one of the layer 2 applications you will see that it has 2 replica pods as directed by the layer2.yaml deployment file.

In the OpenShift terminal window restart the for loop to start sending http requests to layer1. You should now see that layer1 is sending requests on to layer 2 and you should see the IP address of the nodes on which those two layers are running as shown below. This also shows the distribution of traffic to the different versions of layer2. 

[source]
----
"layer1 (v1) [10.128.3.13] ----> layer2 (v1) [10.130.3.146]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v2) [10.130.3.147]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v1) [10.131.1.184]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v2) [10.128.3.12]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v1) [10.130.3.146]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v2) [10.130.3.147]"
"layer1 (v1) [10.128.3.13] ----> layer2 (v1) [10.131.1.184]"
----

In most micro-service based applications messages will not conveniently display application versions or IP addresses as in this example application. Consequently Kiali visualization is very important to show what actually happens in the 'real world'.

Switch to the Kiali browser view and select the graph view. Wait until the traffic starts to appear. You may see some extraneous traffic going to nodes that are not in the current project namespaces. These are genuine messages being send to the Istio system to provide the monitoring capability. To hide the unwanted nodes use a filter in the 'Hide' text field at the top of the graph and use a filter of "namespace!=service-mesh-{{USER_ID}}". Don't include the quote characters.

The Kiali graph view (shown below) is currently displaying the communication into layer 1 and then from layer 1 to layer 2. Layer 2 has a virtual service which is governing the conditions under which layer 2 will get any network traffic such as protocol filtering, path filtering etc. In the absence of a destination rule to govern the flow of traffic a (roughly) 50% - 50% split of traffic is seen between version 1 and version 2 of layer 2. Select "Request percentage" in the second dropdown menu to see the distribution to version 1 and version 2 of layer2. Restart the for loop to send traffic in the terminal window if necessary.

image::service-mesh-07.png[Kiali distribution of traffic to layer 2]

=== Phase 3 - Further multi-versioned applications in the communication chain

The next phase of building the service mesh is to introduce another multi-versioned application and service. 

Change directory to phase 3 and create the new application for layer 3 with the following commands:

[source]
----
cd ../phase3
oc create -f layer3.yaml
----

You will see that four deployments are created for the four different versions of layer3. 

Switch to the OpenShift browser window and ensure that you are using the developer mode on the top left corner, you have the service-mesh-{{USER_ID}} project selected and you are viewing the Topology view. You should see the 'layers' application grouping now has seven micro-services within it. This is shown below:

image::service-mesh-08.png[OpenShift topology view of micro-services]

Under more common circumstances of a development project then names will often be cryptic and it will be hard to gain any understanding of the communication logic, sequence or hierarchy of an overall application. This is when the Kiali visualization view becomes extremely useful. 

To tie the service mesh together for the different versions of layer3 a virtual service and a destination rule will be used. 

.Virtual Services and Destination Rules
****
Virtual services and destination rules work hand-in-hand to define the routing of traffic. The virtual service is evaluated first and decides how to route traffic to a specific destination and then the destination rule is used to direct the traffic for the identified destination. The virtual service used in this phase is shown below:
[source]
----
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: layer3
spec:
  hosts:
  - layer3
  http:
  - match:
    - uri:
        exact: /call-layers
    - uri:
        exact: /get-info        
    - uri:
        exact: /
  - route:
    - destination:
        host: layer3
        subset: v1
      weight: 50
    - destination:
        host: layer3
        subset: v2
      weight: 30
    - destination:
        host: layer3
        subset: v3
      weight: 20
----

The above will direct http traffic with the uri path of /call-layers, /get-info or / sent to application layer3 (spec: -> hosts: -> layer3) to the destinations subset v1 (50% of traffic), subset v2 (30% of traffic) and subset v3 (20% of traffic). At the present time no traffic is directed to subset v4. 

The destination rule associated with the above virtual service is shown below which ties the subsets shown in the virtual service to the specific versions of the applications :

[source]
----
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: layer3
spec:
  host: layer3
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
  - name: v3
    labels:
      version: v3
----

The destination rule defines to where the different subsets will direct traffic. Subset v1 directs traffic to the pod with the label v1 and subset v2 directs traffic to the pod with the label v2 etc.
****

The command below will display all pods and the labels defined on them:

[source]
----
oc get pods -o jsonpath='{range.items[*]}{.metadata.name}{"  "}{.metadata.labels.version}{"\n"}'
----

The result of the above command will be similar to that shown below:

[source]
----
layer1-v1-5cdbdc64bc-hbm77  v1
layer2-v1-747594d6d9-rd586  v1
layer2-v1-747594d6d9-wlrhr  v1
layer2-v2-7f8b4674cc-vbvt9  v2
layer2-v2-7f8b4674cc-zs9lk  v2
layer3-v1-85db7f87c6-rdz8c  v1
layer3-v2-5649897bbf-6f99m  v2
layer3-v3-769cfb5446-jcs4v  v3
layer3-v4-858765c8c9-m5lzf  v4
----

The above shows that there is 1 version for layer1, 2 versions for layer 2 that are replicated pods (two instances) and 4 versions for layer 3.

Destination rules require a virtual services and there cannot be more destinations than virtual services. For this reason when a destination rule is used the virtual service is either created at the same time or the virtual service already exists. 

[source]
----
oc create -f destination-rule-virtual-service-layer3.yaml
----

In the previous test it was seen that there was a 50% - 50% distribution of traffic going into layer 2. The command below will introduce a destination rule and add a distribution clause to the virtual service for layer 2 to distribute the traffic  80% to 20% in favour of version 1.

[source]
----
oc apply -f destination-rule-virtual-service-layer2.yaml
----

Reconfigure layer2 to send messages to layer3 using the command:

[source]
----
oc apply -f layer2.yaml
----

In the OpenShift terminal window recall the for loop that sends messages to the applications and change the total number of messages to 200 and the sleep value from .2 to .5. This will give more time to explore the traffic in Kiali. Execute the command when the changes have been made. You should now see that layer1 is sending requests on to layer 2 which is sending requests on to layer 3 and you should see the IP address of the nodes on which those two layers are running as shown below. You will also see a distribution of workload across layer 3 v1, v2 and v3 in the percentages defined in the virtual service.

[source]
----
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v2 (v2) [10.128.2.145]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v1 (v1) [10.128.2.143]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
"layer1 (v1) [10.130.2.240] ----> layer2 (v1) [10.128.2.151] ----> layer3-v3 (v3) [10.128.2.144]"
----

Of the above 25 calls, 10 are for v1 (40%), 8 are for v2 (32%) and 7 are for v3 (28%). The distribution percentages become more accurate the more messages are sent. When more calls are made the distribution gets closer to the desired values. 

Switch to the Kiali browser view and wait until the traffic starts to appear. On the second to left drop down option menu at the top of the Kiali screen select the option "Requests percentage". This will show the breakdown of traffic similar to that which is shown below:

image::service-mesh-09.png[OpenShift topology view of micro-services]

=== Phase 4 - Service timeout

The service mesh has a capability to manage traffic flow in a number of different ways. This includes a circuit breaker function to remove applications from participation in communication and a timeout function to control the abandonment of communication with a service, to name just two. In this phase a timeout will be introduced to control the traffic flow such that version A of the application layer will force a timeout after 1.5 second and version B will force a timeout after 1 seconds. 

Change directory to phase 3 and create the new applications for layers 2A and 2B with the following commands:

[source]
----
cd ../phase4
oc create -f layer2-A.yaml --save-config
oc create -f layer2-B.yaml --save-config
----

Create the virtual service and destination rule for each of the new applications. The destination rule and virtual service for application 2A is shown below :

[source]
----
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: layer2-a
spec:
  host: layer2-a
  subsets:
  - name: inst-1
    labels:
      instance: instance1
  - name: inst-2
    labels:
      instance: instance2
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: layer2-a
spec:
  hosts:
  - layer2-a
  http:
  - match:
    - uri:
        prefix: /call-layers
    - uri:
        exact: /get-info        
    - uri:
        exact: /
    route:
    - destination:
        host: layer2-a
        port:
          number: 8080
        subset: inst-1
      weight: 80
    - destination:
        host: layer2-a
        port:
          number: 8080
        subset: inst-2
      weight: 20
    timeout: 1.500s
----

The virtual service shows a traffic distribution of 80 % to inst-1 and 20% to inst-2. The final statement shows the timeout that applies to the entire route of 1.5 seconds. 

A similar configuration applies to the virtual service and destination rules for application 2-B with a distribution of 30% to 70% and a timeout of 1 second. 

Create the virtual services and destination rules with the commands :

[source]
----
oc create -f destination-rule-virtual-service-layer2-A.yaml --save-config
oc create -f destination-rule-virtual-service-layer2-B.yaml --save-config
----

Modify layer 1 application so that it sends traffic to applications 2A and 2B.

[source]
----
oc apply -f layer1.yaml
----

In the OpenShift terminal window recall the for loop that sends messages to the applications and execute it again.

You should now see that layer1 is sending requests on to layer 2a (instances 1 and 2) and to layer 2b (instances 1 and 2) Take a look at the graph in Kiali and you will also see a distribution of workload across layer 2 in the percentages defined in the virtual service.

[source]
----
layer1 (v1) [10.128.2.62] ----> layer2-a (instance-2) [10.128.2.60]
layer1 (v1) [10.128.2.62] ----> layer2-a (instance-1) [10.128.2.59]
layer1 (v1) [10.128.2.62] ----> layer2-a (instance-1) [10.128.2.59]
layer1 (v1) [10.128.2.62] ----> layer2-b (instance-1) [10.128.2.61]
layer1 (v1) [10.128.2.62] ----> layer2-b (instance-2) [10.131.0.86]
layer1 (v1) [10.128.2.62] ----> layer2-a (instance-2) [10.128.2.60]
layer1 (v1) [10.128.2.62] ----> layer2-a (instance-2) [10.128.2.60]
----

==== Introducing application delay

To show the impact of the timeout function a different rest endpoint is used. Reconfigure the ROUTE environment variable to use the alternative endpoint with the command :

[source]
----
export ROUTE=$(oc get route -o jsonpath='{.items[0].spec.host}{"/call-layers-sleep"}')
----

Call the applications with a delay of 900ms. This should result in no interruption to service. Execute the following shell command to make 100 calls.

[source]
----
for i in {1..100}; do curl $ROUTE:900; echo "";done
----

This will result in a display similar to that which is shown below. Instances 1 and 2 of layers 2a and 2b are responding.

[source]
----
layer1 (v1) [10.128.2.62] sleep (900 ms) ----> layer2-b (instance-1) [10.128.2.61] sleep (900 ms)
layer1 (v1) [10.128.2.62] sleep (900 ms) ----> layer2-a (instance-1) [10.128.2.59] sleep (900 ms)
layer1 (v1) [10.128.2.62] sleep (900 ms) ----> layer2-b (instance-2) [10.131.0.86] sleep (900 ms)
layer1 (v1) [10.128.2.62] sleep (900 ms) ----> layer2-b (instance-1) [10.128.2.61] sleep (900 ms)
layer1 (v1) [10.128.2.62] sleep (900 ms) ----> layer2-b (instance-2) [10.131.0.86] sleep (900 ms)
layer1 (v1) [10.128.2.62] sleep (900 ms) ----> layer2-a (instance-1) [10.128.2.59] sleep (900 ms)
layer1 (v1) [10.128.2.62] sleep (900 ms) ----> layer2-a (instance-1) [10.128.2.59] sleep (900 ms)
layer1 (v1) [10.128.2.62] sleep (900 ms) ----> layer2-b (instance-2) [10.131.0.86] sleep (900 ms)
----

Increase the delay to 1100 ms using the command :

[source]
----
for i in {1..100}; do curl $ROUTE:1100; echo "";done
----

This will result in a display similar to that which is shown below. Instances 1 and 2 of layers 2a are responding, while the delayed response from instances 1 and 2 of layer 2b are being timed out.

[source]
----
layer1 (v1) [10.128.2.62] sleep (1100 ms) ----> upstream request timeout
layer1 (v1) [10.128.2.62] sleep (1100 ms) ----> layer2-a (instance-1) [10.128.2.59] sleep (1100 ms)
layer1 (v1) [10.128.2.62] sleep (1100 ms) ----> upstream request timeout
layer1 (v1) [10.128.2.62] sleep (1100 ms) ----> upstream request timeout
layer1 (v1) [10.128.2.62] sleep (1100 ms) ----> layer2-a (instance-1) [10.128.2.59] sleep (1100 ms)
layer1 (v1) [10.128.2.62] sleep (1100 ms) ----> layer2-a (instance-2) [10.128.2.60] sleep (1100 ms)
layer1 (v1) [10.128.2.62] sleep (1100 ms) ----> layer2-a (instance-2) [10.128.2.60] sleep (1100 ms)
layer1 (v1) [10.128.2.62] sleep (1100 ms) ----> layer2-a (instance-1) [10.128.2.59] sleep (1100 ms)
----

Increase the delay to 1600 ms using the command :

[source]
----
for i in {1..100}; do curl $ROUTE:1600; echo "";done
----

This will result in a display similar to that which is shown below in which all calls are being timed out. 

[source]
----
layer1 (v1) [10.128.2.62] sleep (1100 ms) ----> upstream request timeout
layer1 (v1) [10.128.2.62] sleep (1100 ms) ----> upstream request timeout
----

While the for loop is running make a change to the timeout of one of the virtual services to increase the delay to 2500 ms. This can be done in two different ways. 

1. Make a change to one the virtual service files using the vi editor and then re-apply the virtual service using the following :

[source]
----
vi destination-rule-virtual-service-layer2-A.yaml
oc apply -f destination-rule-virtual-service-layer2-A.yaml

or

vi destination-rule-virtual-service-layer2-B.yaml
oc apply -f destination-rule-virtual-service-layer2-B.yaml
----

Alternatively use the Kiali browser window, switch to the istio-config section on the left hand side and select the virtual service for either layer2-A or layer2-A. Edit the yaml within the window to alter the timeout value and save the changes. One of the good things about using this editor is the immediate validation of the yaml code.

Observe that traffic starts to be allowed through to that application only.

Take a look at the traffic flow in the graph view of Kiali and you should see a display similar to that which is shown below (once Kiali has had the opportunity to catch up).

image::service-mesh-10.png[Traffic distribution with errors]

The above image shows red to indicate the communication that is being rejected by the timeout. 

=== Cleaning up

To tidy up the cluster now that the chapter is complete please use the command

[source]
----
oc delete project service-mesh-{{USER_ID}}
----









