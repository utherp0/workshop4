Author: Mark Roberts (feedback to mroberts@redhat.com)

=== Introduction

****
For many years teams have created automation pipelines to build, unit test, analyse and deploy applications in a variety of tool-chains. Some such tool-chains (Jenkins for one) pre-date the popularization of containers and are now being questioned for their fit for the delivery of cloud native applications. While we are at pains not to criticize Jenkins (we are big users and fans) there is scope to look at alternative approaches for cloud native applications.*

OpenShift Pipelines are based on the Tekton open source project and they provide a Kubernetes style, resource based approach to the construction of pipelines. Tasks are defined as small units of operations (typically 10 to 15 lines of YAML) and such tasks are grouped together into taskruns or pipelines for execution.

A new command line exists for the execution of Tekton commands and a graphical user interface can be added to the cluster to provide a simple way to run tasks and to observe running or completed tasks.
****

The Tekton project can be found here : https://tekton.dev/[https://tekton.dev/, window="_blank"]

Further documentation on the specifics of Tekton can be found on the github site here : https://github.com/tektoncd/pipeline[https://github.com/tektoncd/pipeline, window="_blank"]

=== Tasks

==== View pipeline assets

View the assets for the workshop using:

[source]
----
cd /workspace/workshop4/attendee/tekton/
ls -al
----

You should now see a list of yaml files that are used during the remainder of this chapter.

==== Project creation

Create a new project for the pipeline work called pipelines-{{USER_ID}} using the command

[source]
----
oc new-project pipelines-{{USER_ID}}
----

==== Simple task creation and execution

TIP: In the simplest format a task can be executed by a taskrun object. The diagram below shows a simple taskrun calling a single task

image::pipelines-1.png[Simple pipeline with a task and taskrun]

.Tekton command line
****
A new command line utility is used to manage the Tekton command line. The commands cover the various different pipeline objects such as task, taskrun, pipeline, pipelinerun,  resources, cluster tasks and conditions.

The Tekton command line interface is built into the terminal that you create as a pre-requisite for this workshop so you don't have to install anything right now. However, if you want to install the interface on your own workstation then it is available for download from here : https://github.com/tektoncd/cli[https://github.com/tektoncd/cli, window="_blank"] 

To use the command simply type 'tkn' and you will see help regarding the objects and to get help on a specific object use 'tkn <object> --help'
****

To execute the above pipeline use the following commands to create the pipeline objects. Note that when creating the taskrun objects the associated task(s) will run immediately.

[source]
----
oc create -f task-1.yaml 
oc create -f taskrun-1.yaml 
tkn taskrun ls
----

The response from the last command will display a line similar to the following:

[source]
----
NAME          STARTED           DURATION      STATUS
task-run-1    9 seconds ago     ---           Running(Pending) 
----

Repeat the final command a few times until you see it change to be similar to the following:

[source]
----
NAME          STARTED           DURATION      STATUS
task-run-1    40 seconds ago    21 seconds    Succeeded 
----

The result of running the task can then be viewed by executing the following command:

[source]
----
tkn taskrun logs task-run-1
----

[source]
----
[echo-statement-1] This is my first task in Tekton

[echo-statement-2] ------------------------------------------------------------
[echo-statement-2]   - This is a multi-line comment
[echo-statement-2]   - This is useful as a separator but each line has
[echo-statement-2]   - the title repeated next to it using different colours
[echo-statement-2]   - which helps with the identification of different tasks.
[echo-statement-2]  ------------------------------------------------------------
[echo-statement-2] 
----

TIP: Note that the command response above uses different colours for each block of command result titles in the [ ] brackets. This helps to differential between the response for each step.

=== Pipelines

Pipelines are used to manage the execution of a series of tasks within a pipeline. The example pipeline below is used to execute the Tekton tasks : task-1, task-2 and task-3. Remember that each Tekton task can have multiple steps within it.

[source]
----
apiVersion: tekton.dev/v1alpha1
kind: Pipeline
metadata:
  name: pipeline-1
spec:
  tasks:
  - name: task-1
    taskRef:
      name: task-1
  - name: task-2
    taskref:
      name: task-2
  - name: task-3
    taskref:
      name: task-3
----

Before executing this pipeline create the required additional resources with the commands :

[source]
----
oc create -f task-2.yaml 
oc create -f task-3.yaml 
oc create -f pipeline-1.yaml
----

Execute the pipeline with the following Tekton task

[source]
----
tkn pipeline start pipeline-1
----

Once you have executed the command switch back to the OpenShift console. If you select the Developer view you will find there is a menu option on the left hand side labelled 'Pipelines'. Select this option and the screen should look like this:

image::pipelines-2.png[Example Pipelines UI]

Once the pipeline is indicated to have finished by showing 'Succeeded' in the 'Last Run Status' column, go back to the terminal and enter the command suggested by the response to the tkn command - it will look similar to this:

[source]
----
tkn pipelinerun logs pipeline-1-run-kx95g -f
----

Enter the command as provided by the tkn command and the response should look something like this:

[source]
----
Pipelinerun started: pipeline-1-run-ffxsk
Showing logs...
[task-2 : what-directory] /workspace

[task-2 : describe-command] ------------------------------------------------------------
[task-2 : describe-command]   - Openshift oc command line example 
[task-2 : describe-command]  ------------------------------------------------------------
[task-2 : describe-command] 

[task-2 : oc-version] Client Version: unknown
[task-2 : oc-version] Kubernetes Version: v1.14.6+76aeb0c

[task-3 : echo-statement-3] echo - statement 3
[task-1 : echo-statement-1] This is my first task in Tekton


[task-3 : echo-statement-4] echo - statement 4

[task-1 : echo-statement-2] ------------------------------------------------------------
[task-1 : echo-statement-2]   - This is a multi-line comment
[task-1 : echo-statement-2]   - This is useful as a separator but each line has
[task-1 : echo-statement-2]   - the title repeated next to it using different colours
[task-1 : echo-statement-2]   - which helps with the identification of different tasks.
[task-1 : echo-statement-2]  ------------------------------------------------------------
----

TIP: There may be an issue in the order of the execution above. The order of the pipeline expected is different to the order observed:

[source]
----
   Expected               Actual
task 1 - step 1       task 2 - step 1
task 1 - step 2       task 2 - step 2
task 2 - step 1       task 2 - step 3
task 2 - step 2       task 3 - step 1
task 2 - step 3       task 1 - step 1
task 3 - step 1       task 3 - step 2
task 3 - step 2       task 1 - step 2
----

TIP: In some pipelines the order of execution may not matter but if it does the order can be managed by the addition of the 'runAfter' directive to a specific task as shown in the update to the pipeline-1 pipeline shown below:

[source]
----
apiVersion: tekton.dev/v1alpha1
kind: Pipeline
metadata:
  name: pipeline-1
spec:
  tasks:
  - name: task-1
    taskRef:
      name: task-1
  - name: task-2
    taskref:
      name: task-2
    runAfter: 
    - task-1
  - name: task-3
    taskref:
      name: task-3
    runAfter:
    - task-2
----

Make the above changes to the pipeline-1.yaml file by using vi:

[source]
----
vi pipeline-1.yaml
----

Press [ESC] then i to edit/insert, make the changes to the file, then press [ESC] and type :wq[RETURN] to save the changes

Now replace the existing pipeline using the following commands:

[source]
----
oc delete pipeline pipeline-1
oc create -f pipeline-1.yaml
tkn pipeline start pipeline-1
----

As soon as you enter the last command switch back to the console and watch the pipeline complete, note the synchronous order of the steps.

=== Viewing pipelines through the Web UI

In the OpenShift console you will see the pipeline recently created and it will show a green bar to the right indicating the previous successful execution of the pipeline, as shown below. Note that the green bar will display dark blue sections for running tasks, light blue sections for pending tasks, green for completed and red for failed.

image::pipelines-3.png[Pipeline view showing a completed pipeline run]

From the three dot menu on the right hand side it is possible to start a run of the pipeline. Do this now and watch as the screen changes to show the details of the pipeline run as shown below:

image::pipelines-4.png[Pipelinerun in progress]

Each block can be clicked on to show the details of the steps within the task. Experiment with the different screens to look at the details of the running or completed tasks.

=== Task inputs

There will be scenarios where it is necessary to provide specific parameters to a pipeline process and the underlying tasks that the pipeline call.

There are two mechanisms for getting specific values into tasks :

* parameters - used to provide specific values to tasks at runtime. If a parameter is declared it must either have a default value defined within the task or it must have a value supplied from a calling taskrun or pipeline run.

* pipeline resources - a reference to a defined resource object that can be accessed by a Tekton pipeline. If a resource is referenced by a task then the resource must exist unless it has been defined as an optional resource in the task definition.

.Pipeline Resource Types
****

The following pipeline resource types exist :

* Git Resource - The git resource identifies a git repository, that contains the source code to be built by the pipeline. The resource can point to a specific branch or commit and can extract content from a specific directory.

* Pull Request - Can be used as an input resource to identify specific meta data about a pull request. if used as an output a pull request can be updated with changes made during the pipeline process.

* Image - An image to be created as part of the pipeline process.

* Cluster Resource - A different cluster to the cluster on which the pipeline is running. This can be used to deploy content to an alternative cluster as part of a deployment pipeline process.

* Storage Resource - Blob storage that contains either an object or directory. 

* Cloud Event Resource - A cloud event that is sent to a target URI upon completion of a TaskRun.

Further details on the options for all of the above resources is included here : https://github.com/tektoncd/pipeline/blob/master/docs/resources.md[https://github.com/tektoncd/pipeline/blob/master/docs/resources.md, window="_blank"]

****

==== Task input example

The task defined in task-4.yaml uses both parameters and pipeline resources to get information into the task. This allows a generic task to be written with specific values supplied to it from the taskrun. The Taskrun object acts as a 'value provider' giving specific values for parameters and referencing specific pipeline resources. The following diagram shows the relationship between the three specific objects.

image::pipelines-5.png[Task and resource relationship]

As shown above the task has place-holders for two parameters. The first parameter has a value defined within the taskrun. The second parameter has a default value so it is not essential to provide a value for it in the taskrun. Both parameters are referenced from the steps of the task using the notation $(inputs.params.<parameter-name>).

The task also defines a resource object called git-repo-simple-rest of type git. Within the taskrun an input resource object is defined with the same name (git-repo-simple-rest) referring to a pipeline resource object called git-repo-simple-rest-resource. A pipeline resource object is created from the yaml file git-resources.yaml which makes a reference to the actual git repository.

To create the resource object go back to the terminal app and execute the following command :

[source]
----
oc create -f git-resources.yaml
----

To view the resources in the project use the command:

[source]
----
tkn resources list
----

The response will be :

[source]
----
NAME                      TYPE   DETAILS
git-repo-simple-rest-resource   git    url: https://github.com/marrober/simpleRest.git
----

To execute task 4 and view the output execute the following commands :

[source]
----
oc create -f task-4.yaml 
oc create -f taskrun-4.yaml 
tkn taskrun ls
----

Repeat the final command a few times until task-run-4 has a status of Succeeded. When the task has completed execute the command below to see the output results.

[source]
----
tkn taskrun logs task-run-4
----

The use of pipeline resource objects for git repositories and created images (as output resources) helps teams to create generic build, test and deploy pipelines that can be reused across multiple projects where the projects simply define the custom pipeline resource objects that are specific to their project or environment.

=== Workspaces and Volumes

Workspaces allow you to organize the content used by tasks and the assets that are produced by tasks. This can be useful to add structure to the content during large complex pipelines. 

*Workspaces* are storage structures within the pod that runs the containers of the pipeline and workspaces are scoped at the task level. Separate steps within a task can see the same workspace. 

*Volumes* are similar to workspaces except for the fact that they are backed by persistent volumes. This ensures that content written to the volume is accessible by steps from multiple tasks, allowing for a greater separation of steps into different tasks. For example a generic build task could be used to create an executable, writing the deliverable to a volume. A separate testing task could then be invoked by a pipeline to perform tests against the newly created deliverable. Accessing the file via a volume will work for the two separate tasks.

Task 5 has steps for creating files in the workspace and in a volume, followed by steps to display the files in the workspace and the volume which work fine. Task 6 only has tasks for attempting to display the content of the workspace and the volume. Since the workspace in task 6 is a different workspace to that used in task 5 there is no content to display. The volume however shows the file written in the step in task 5. Tasks 5 and 6 are orchestrated by the pipeline called pipeline-5.

Create the persistent volume claim to use in this exercise with the command:

[source]
----
oc create -f persistentvolumeclaim.yaml
----

Create tasks 5 and 6:

[source]
----
oc create -f task-5.yaml
oc create -f task-6.yaml
----

Create the pipeline task:

[source]
----
oc create -f pipeline-5.yaml 
----

TIP: The persistent volume will show that it is in a pending state after creation as no resource has attempted to consume it. After the task has been executed look again at the persistent volume and it will show that it is bound.

To see the state of the pvc enter the following:

[source]
----
oc get pvc
----

Before executing the task the state of the pvc should be as follows

[source]
----
NAME                    STATUS        VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
tekton-task-cache-pvc   Pending                                                                            gp2            4s
----

Once the pipeline has completed (you will run it after this) the pvc will indicate itself as bound - try it after the pipeline has completed

[source]
----
NAME                    STATUS        VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
tekton-task-cache-pvc   Bound         pvc-1d894a93-2646-11ea-9f45-0a9970779e5c   1Gi        RWO            gp2            2m2s
----

Execute the pipeline using the following command in the terminal

[source]
----
tkn pipeline start pipeline-5
----

Now switch to the OpenShift console. Select the Pipelines entry on the left side of the Developer panel.

image::pipelines-6.png[Two completed pipelines]

You can click on the pipeline-run (labelled pipeline-5-run-XXXXX) and examine the logs for each of the tasks. 

image::pipelines-7.png[Task details]

To examine the pipeline run in the terminal window use the command :

[source]
----
tkn pipelinerun logs pipeline-5-run-XXXXX
----

Replace the XXXX with the information reported on screen after the execution of the tkn pipeline start command.

The output will be similar to that that is shown below. Within task 5 the first step creates a file called /workspace/message. The second step displays the file name and the content of the file within the workspace. The third step creates a file in the persistent volume and the fourth step displays the file name and the content of the file within the volume. 

Within task 6 the first step displays the contents of the workspace. Note that this is empty because the workspace is unique to the task. The second step of task 6 shows the content of the persistent volume which is the same a that which was reported for step 5. This shows that workspaces can be used for sharing data between steps in the same task and volumes should be used for sharing data between steps within different tasks.

[task-5 : create-a-file-in-workspace] /workspace/message

[task-5 : view-workspace-content] message
[task-5 : view-workspace-content] This is a file in the workspace

[task-5 : create-a-file-in-volume] /var/run/message

[task-5 : view-volume-content] lost+found
[task-5 : view-volume-content] message
[task-5 : view-volume-content] secrets
[task-5 : view-volume-content] This is a file in the volume

[task-6 : view-workspace-content] view workspace content
[task-6 : view-workspace-content] total 0
[task-6 : view-workspace-content] drwxrwsrwx. 2 root 1000800000  6 May  1 14:17 .
[task-6 : view-workspace-content] drwxr-xr-x. 1 root root       37 May  1 14:17 ..

[task-6 : view-volume-content] lost+found
[task-6 : view-volume-content] message
[task-6 : view-volume-content] secrets
[task-6 : view-volume-content] This is a file in the volume

==== Cleaning up

From the OpenShift browser window click on 'administrator' and then 'Projects' on the left hand side menu.

In the triple dot menu next to your own project (pipelines-{{USER_ID}}) select ‘Delete Project’
Type pipelines-{{USER_ID}}’ such that the Delete button turns red and is active.

Press Delete to remove the project.










